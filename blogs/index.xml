<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" 
  xmlns:content="http://purl.org/rss/1.0/modules/content/" 
  xmlns:dc="http://purl.org/dc/elements/1.1/" 
  xmlns:atom="http://www.w3.org/2005/Atom" 
  xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" 
  xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>Blogs on Laniakea</title>
    <link>/blogs/</link>
    <description>Recent content in Blogs on Laniakea</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>xxuan@mail.ustc.edu.cn (Xuan)</managingEditor>
    <webMaster>xxuan@mail.ustc.edu.cn (Xuan)</webMaster>
    <copyright>&amp;copy;{year}, All Rights Reserved</copyright>
    <lastBuildDate>Tue, 30 Aug 2022 16:56:33 +0800</lastBuildDate>
    
        <atom:link href="/blogs/index.xml" rel="self" type="application/rss+xml" />
    
    
    

      
      <item>
        <title>Observer Pattern</title>
        <link>/blogs/observer-pattern/</link>
        <pubDate>Tue, 30 Aug 2022 16:56:33 +0800</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 30 Aug 2022 16:56:33 +0800</atom:modified>
        <guid>/blogs/observer-pattern/</guid>
        <description>&lt;p&gt;è§‚å¯Ÿè€…æ¨¡å¼æ˜¯å¸¸è§çš„è®¾è®¡æ¨¡å¼ä¹‹ä¸€.&lt;/p&gt;</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
          
            
              <category>Design Pattern</category>
            
          
        
      </item>
      
      <item>
        <title>èµ›åšæœ‹å…‹, è°ƒé…’å¸ˆä¸ç°å®</title>
        <link>/blogs/va11/</link>
        <pubDate>Sun, 04 Jul 2021 23:12:54 +0800</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sun, 04 Jul 2021 23:12:54 +0800</atom:modified>
        <guid>/blogs/va11/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Time to mix drinks and change lives&lt;/p&gt;
&lt;/blockquote&gt;</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>Library Support Guidance</title>
        <link>/blogs/lib-guidance/</link>
        <pubDate>Thu, 06 Feb 2020 15:44:39 +0800</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 06 Feb 2020 15:44:39 +0800</atom:modified>
        <guid>/blogs/lib-guidance/</guid>
        <description>MathJax A JavaScript display engine for mathematics that works in all browsers.No more setup for readers. It just works.
When \(a \ne 0\), there are two solutions to \((ax^2 + bx + c = 0)\) and they are \[x = {-b \pm \sqrt{b^2-4ac} \over 2a}.\]
ChartJS Simple yet flexible JavaScript charting for designers &amp;amp; developers
{ &amp;#34;type&amp;#34;: &amp;#34;bar&amp;#34;, &amp;#34;data&amp;#34;: { &amp;#34;labels&amp;#34;: [&amp;#34;One&amp;#34;, &amp;#34;Two&amp;#34;, &amp;#34;Three&amp;#34;, &amp;#34;Four&amp;#34;, &amp;#34;Five&amp;#34;, &amp;#34;Six&amp;#34;], &amp;#34;datasets&amp;#34;: [{ &amp;#34;label&amp;#34;: &amp;#34;# of Votes&amp;#34;, &amp;#34;data&amp;#34;: [12, 19, 3, 5, 3, 8] }] } } { &amp;#34;type&amp;#34;: &amp;#34;line&amp;#34;, &amp;#34;data&amp;#34;: { &amp;#34;labels&amp;#34;: [&amp;#34;One&amp;#34;, &amp;#34;Two&amp;#34;, &amp;#34;Three&amp;#34;, &amp;#34;Four&amp;#34;, &amp;#34;Five&amp;#34;, &amp;#34;Six&amp;#34;], &amp;#34;datasets&amp;#34;: [ { &amp;#34;label&amp;#34;: &amp;#34;# of Votes&amp;#34;, &amp;#34;data&amp;#34;: [12, 19, 3, 5, 2, 3], &amp;#34;backgroundColor&amp;#34;:&amp;#34;transparent&amp;#34;, &amp;#34;borderColor&amp;#34;:&amp;#34;orange&amp;#34; }, { &amp;#34;label&amp;#34;: &amp;#34;Some other set&amp;#34;, &amp;#34;data&amp;#34;: [15, 8, 13, 5, 5, 9], &amp;#34;backgroundColor&amp;#34;:&amp;#34;transparent&amp;#34;, &amp;#34;borderColor&amp;#34;:&amp;#34;#44ccff&amp;#34; } ] } } FLowChart flowchart.</description>
        
        <dc:creator>Choi</dc:creator>
        
        <media:content url="image/store/mathbook.png" medium="image"><media:title type="html">featured image</media:title></media:content>
        
        
          
            
              <category>markdown</category>
            
          
        
        
          
            
              <category>syntax</category>
            
          
        
        
          
            
              <category>Themes Guide</category>
            
          
        
      </item>
      
      <item>
        <title>Markdown Basic Syntax</title>
        <link>/blogs/basic/</link>
        <pubDate>Thu, 06 Feb 2020 00:43:57 +0800</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 06 Feb 2020 00:43:57 +0800</atom:modified>
        <guid>/blogs/basic/</guid>
        <description>&lt;p&gt;This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.&lt;/p&gt;</description>
        
        <dc:creator>Choi</dc:creator>
        
        <media:content url="image/store/markdown.png" medium="image"><media:title type="html">featured image</media:title></media:content>
        
        
          
            
              <category>markdown</category>
            
          
        
        
          
            
              <category>syntax</category>
            
          
        
        
          
            
              <category>Themes Guide</category>
            
          
        
      </item>
      
      <item>
        <title>Pythonæ•°æ®åˆ†æç¬”è®°2 pandasåŸºç¡€</title>
        <link>/blogs/2017-09-28-pandas/</link>
        <pubDate>Fri, 29 Sep 2017 00:30:14 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 29 Sep 2017 00:30:14 +0000</atom:modified>
        <guid>/blogs/2017-09-28-pandas/</guid>
        <description>å…¨é¢ç¿»æ–°çš„pandasä»‹ç», ç¯‡å¹…è¾ƒé•¿, è¯·å–„ç”¨å³ä¸‹è§’ç›®å½•! 1 2 import numpy as np import pandas as pd æ•°æ®ç»“æ„ Series 1 Series(data=None, index=None, dtype=None, name=None, copy=False, , fastpath=False) data: å¯éå†åºåˆ—æ•°æ® index: ç´¢å¼•, hsahabl</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>pandas</category>
            
          
            
              <category>python-data-analysis</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Pythonæ ¸å¿ƒç¼–ç¨‹ç¬”è®°5 æ‰©å±•Python</title>
        <link>/blogs/2017-09-27-python-extend/</link>
        <pubDate>Wed, 27 Sep 2017 23:59:35 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 27 Sep 2017 23:59:35 +0000</atom:modified>
        <guid>/blogs/2017-09-27-python-extend/</guid>
        <description>å·¦æ‰‹C++, å³æ‰‹Python, æ€§èƒ½ä¸è¡¨è¾¾åŠ›çš„å®Œç¾èåˆ Pythonæ‰©å±• å®˜æ–¹æ–‡æ¡£ pythonåœ¨è®¾è®¡ä¹‹åˆå°±è€ƒè™‘åˆ°è®©æ¨¡å—çš„å¯¼å…¥æœºåˆ¶è¶³å¤ŸæŠ½è±¡, æŠ½è±¡åˆ°è®©</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Pythonæ ¸å¿ƒç¼–ç¨‹ç¬”è®°4 å¤šçº¿ç¨‹</title>
        <link>/blogs/2017-09-26-python-thread/</link>
        <pubDate>Tue, 26 Sep 2017 21:54:13 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 26 Sep 2017 21:54:13 +0000</atom:modified>
        <guid>/blogs/2017-09-26-python-thread/</guid>
        <description>å³ä½¿æœ‰GILçš„å­˜åœ¨ä½¿å¾—pythonçš„å¤šçº¿ç¨‹æ˜¾å¾—é¸¡è‚‹, ä½†åœ¨é‡I/Oåº”ç”¨ä¸­è¿˜æ˜¯å¾ˆå®ç”¨, å¹¶ä¸”multiprecessingæ˜¯åŸºäºthreading</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Pythonæ ¸å¿ƒç¼–ç¨‹ç¬”è®°3 é¢å‘å¯¹è±¡ç¼–ç¨‹</title>
        <link>/blogs/2017-09-25-python-oop/</link>
        <pubDate>Mon, 25 Sep 2017 16:54:18 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 25 Sep 2017 16:54:18 +0000</atom:modified>
        <guid>/blogs/2017-09-25-python-oop/</guid>
        <description>pythonæœ‰å¾ˆå¥½çš„OOPç‰¹æ€§, è‡ªç”±åº¦ä¹Ÿéå¸¸å¤§ å‘½åè§„åˆ™ å°é©¼å³°å‘½åæ³•(camel case), é€‚ç”¨äºå˜é‡å: varFirst, verSecond å¤§é©¼å³°å‘½åæ³•, é€‚ç”¨äºç±»å: PersonFirst, PersonSecond ä¸‹åˆ’çº¿å‘½åæ³•</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Pythonæ•°æ®åˆ†æç¬”è®°1 numpy</title>
        <link>/blogs/2017-09-21-numpy/</link>
        <pubDate>Thu, 21 Sep 2017 23:48:31 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 21 Sep 2017 23:48:31 +0000</atom:modified>
        <guid>/blogs/2017-09-21-numpy/</guid>
        <description>ç”¨äº†è¿™ä¹ˆä¹…numpyå±…ç„¶æ²¡æœ‰æ€»ç»“ä¸€ä¸‹ 1 import numpy as np ndarrayå±æ€§ 1 2 # åˆå§‹åŒ– a = np.array([[1, 2], [3, 4]]) 1 2 # ç¬¬ä¸€ç»´çš„ç»´æ•° a.ndim 2 1 2 # æ‰€æœ‰ç»´çš„ç»´æ•° a.shape (2, 2) 1 2 #</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>numpy</category>
            
          
            
              <category>python-data-analysis</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>æ¢¯åº¦æå‡(Gradient Boosting)</title>
        <link>/blogs/2017-09-04-gradient-boosting/</link>
        <pubDate>Mon, 04 Sep 2017 22:05:06 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 04 Sep 2017 22:05:06 +0000</atom:modified>
        <guid>/blogs/2017-09-04-gradient-boosting/</guid>
        <description>è‡ªå·±å†™çš„è€ç‰©äº†, æ•´ç†ä¸€ä¸‹å‘å‡ºæ¥, å¯èƒ½ä¼šä¿®æ”¹ 1. ä»»æ„æŸå¤±å‡½æ•°çš„Boosting æŸå¤±å‡½æ•°çš„ä¸€èˆ¬è¡¨ç¤ºæ˜¯: $$ L(y_i, f(x_i)) $$ è€ƒè™‘ä½¿ç”¨å‰å‘åˆ†æ­¥ç®—æ³•æ±‚è§£ä¸€ä¸ªä»»æ„æŸå¤±</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>gbdt</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Pythonæ ¸å¿ƒç¼–ç¨‹ç¬”è®°2 å‡½æ•°å¼ç¼–ç¨‹</title>
        <link>/blogs/2017-08-20-python-functional-programming/</link>
        <pubDate>Sun, 20 Aug 2017 18:22:10 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sun, 20 Aug 2017 18:22:10 +0000</atom:modified>
        <guid>/blogs/2017-08-20-python-functional-programming/</guid>
        <description>ä¸å­¦å¥½å‡½æ•°å¼ç¼–ç¨‹, æ€»è§‰å¾—äººç”Ÿæœ‰é—æ†¾ ä»€ä¹ˆæ˜¯å‡½æ•° pythonå‡½æ•°å¯ä»¥è¿”å›ä¸€ä¸ªå€¼æˆ–å¯¹è±¡, ä½†è¿”å›ä¸€ä¸ªå®¹å™¨å¯¹è±¡çš„æ—¶å€™çœ‹èµ·æ¥åƒæ˜¯è¿”å›äº†å¤šä¸ªå€¼: return &#39;abc&#39;, &#39;de</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Pythonæ ¸å¿ƒç¼–ç¨‹ç¬”è®°1 åŸºç¡€çŸ¥è¯†</title>
        <link>/blogs/2017-08-18-core-python-programming-1/</link>
        <pubDate>Fri, 18 Aug 2017 13:42:39 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 18 Aug 2017 13:42:39 +0000</atom:modified>
        <guid>/blogs/2017-08-18-core-python-programming-1/</guid>
        <description>è¿™æœ¬ä¹¦ç¿»è¯‘ç¨€çƒ‚, ç„¶è€Œæˆ‘è¿˜æ˜¯å¿ç€çœ‹å®Œäº†ç¬¬ä¸€éƒ¨åˆ† PythonåŸºç¡€ åŸºæœ¬é£æ ¼æŒ‡å— è·¨è¡Œä»£ç å¯ä»¥ä½¿ç”¨åæ–œæ \ å˜é‡èµ‹å€¼é€šè¿‡å¼•ç”¨ä¼ é€’ pythonä¸æ”¯æŒ++,</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Poisson Distribution Summary</title>
        <link>/blogs/2017-08-08-poisson/</link>
        <pubDate>Tue, 08 Aug 2017 15:47:56 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 08 Aug 2017 15:47:56 +0000</atom:modified>
        <guid>/blogs/2017-08-08-poisson/</guid>
        <description>æ³Šæ¾åˆ†å¸ƒæ˜¯éšæœºè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªé‡è¦åˆ†å¸ƒ Poissonåˆ†å¸ƒçš„ç›´è§‚è§£é‡Š å®šä¹‰ $$ {\displaystyle P(k{\text{ events in interval}})=e^{-\lambda }{\frac {\lambda ^{k}}{k!}}} $$ that expresses the probability of a given number of events occurring in a fixed interval of time and/or space if these events occur with a known average</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>stat</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>æŸåŠ¨æ€è§„åˆ’å°é¢˜</title>
        <link>/blogs/2017-08-07-dp1/</link>
        <pubDate>Mon, 07 Aug 2017 16:43:15 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 07 Aug 2017 16:43:15 +0000</atom:modified>
        <guid>/blogs/2017-08-07-dp1/</guid>
        <description>å¥½åƒæ˜¯è°·æ­Œé¢è¯•é¢˜&amp;hellip;ä¸­æ¯”è¾ƒå¼±æ™ºçš„ è¾“å…¥: ä¸€ä¸ªm*nçŸ©é˜µary, çŸ©é˜µå…ƒç´ åªæœ‰0å’Œ1 è¾“å‡º: å¯»æ‰¾ä»å·¦ä¸Šåˆ°å³ä¸‹çš„è¿ç»­è·¯å¾„ä¸­æœ€é•¿çš„è·¯å¾„é•¿åº¦(</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>é¢è¯•é¢˜</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>æ—¥æ¨</title>
        <link>/blogs/2017-08-03-musicdaily/</link>
        <pubDate>Thu, 03 Aug 2017 20:31:19 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 03 Aug 2017 20:31:19 +0000</atom:modified>
        <guid>/blogs/2017-08-03-musicdaily/</guid>
        <description>ğŸµ Aug 3 {% nemusic 31477465 iframe 0 &amp;lsquo;{&amp;ldquo;width&amp;rdquo;:320, &amp;ldquo;height&amp;rdquo;:66}&amp;rsquo; %} Do you hold your breath and make up your mind? Can you calculate in space and time? Marit Larsenæ¥è‡ªæŒªå¨, æ—©å¹´æ˜¯M2Mçš„ä¸€å‘˜, 02å¹´ç»„åˆè§£æ•£åå•é£ Maritçš„å—“éŸ³ç”œç¾</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>melody</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>18å¹´ç§‹å­£é˜…è¯»è®¡åˆ’</title>
        <link>/blogs/2017-08-03-redinglist/</link>
        <pubDate>Thu, 03 Aug 2017 01:30:20 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 03 Aug 2017 01:30:20 +0000</atom:modified>
        <guid>/blogs/2017-08-03-redinglist/</guid>
        <description>åŒ…æ‹¬ä¹¦å’Œpaperå’Œæ„Ÿå…´è¶£çš„topic æ¨èç³»ç»Ÿå®æˆ˜ å¥½çš„æ¨èç³»ç»Ÿ åˆ©ç”¨ç”¨æˆ·è¡Œä¸ºæ•°æ® æ¨èç³»ç»Ÿå†·å¯åŠ¨é—®é¢˜ åˆ©ç”¨ç”¨æˆ·æ ‡ç­¾æ•°æ® åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ åˆ©ç”¨ç¤¾äº¤ç½‘ç»œæ•°</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>ChinaJoy 2017çºªå® å¤šå›¾æ€çŒ«</title>
        <link>/blogs/2017-08-01-chinajoy/</link>
        <pubDate>Tue, 01 Aug 2017 20:53:01 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 01 Aug 2017 20:53:01 +0000</atom:modified>
        <guid>/blogs/2017-08-01-chinajoy/</guid>
        <description>I used to love ruining the weekend alone. But now it just drives me mad æ„Ÿè°¢åŸºå‹æŠ½ç©ºä¸€èµ·æµªè´¹è¿™ä¸ªå‘¨æœ«, æ²¡æœ‰ä»–åœ¨å‰é¢å½“Tæˆ‘å¯èƒ½å°±æŒ¤ä¸å‡ºåœºé¦†äº†( ä¸Šæµ·æ–°å›½é™…åšè§ˆä¸­å¿ƒ(SNIEC) è§„æ¨¡: 7ä¸ª</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>photograph</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>å·¥åŠè£…ä¿®è®°å½•</title>
        <link>/blogs/2017-07-26-new-start/</link>
        <pubDate>Thu, 27 Jul 2017 01:31:19 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 27 Jul 2017 01:31:19 +0000</atom:modified>
        <guid>/blogs/2017-07-26-new-start/</guid>
        <description>å¾ˆä¹…æ²¡æœ‰åŠ¨blogäº†. ä¿®æ•´äº†ä¸€ä¸‹, å¸Œæœ›èƒ½åšå¾—æœ‰è¶£ä¸€ç‚¹, åˆ«è€æ›´æ–°å†·å†°å†°çš„æŠ€æœ¯æ–‡, ä¹Ÿå†™ç‚¹åˆ«çš„, ç‹—çªä¹Ÿå¾—æœ‰ä¸ªçªæ ·æ˜¯ä¸æ˜¯(x æ›´æ¢ä¸»é¢˜(æ„Ÿè°¢åŸä½œè€…Li</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>æ•°æ®å¯è§†åŒ–å·¥å…·SeabornæŒ‡å—</title>
        <link>/blogs/2017-03-29-seaborn/</link>
        <pubDate>Wed, 29 Mar 2017 23:30:01 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 29 Mar 2017 23:30:01 +0000</atom:modified>
        <guid>/blogs/2017-03-29-seaborn/</guid>
        <description>Seabornæ˜¯åŸºäºmatplotlibçš„å°è£…, ä½¿å¾—åˆ¶ä½œå›¾è¡¨æ›´ä¸ºç®€ä¾¿ ä¸€ç»´æ•°æ®çš„åˆ†æ 1 2 3 4 5 6 7 8 9 %matplotlib inline import numpy as np import pandas as pd from scipy import stats, integrate import matplotlib.pyplot as plt import</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>seaborn</category>
            
          
            
              <category>matplotlib</category>
            
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>pandasé€ŸæŸ¥</title>
        <link>/blogs/2017-03-29-pandas-10min/</link>
        <pubDate>Wed, 29 Mar 2017 18:07:25 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 29 Mar 2017 18:07:25 +0000</atom:modified>
        <guid>/blogs/2017-03-29-pandas-10min/</guid>
        <description>pandas, pythonæ ˆçš„æ•°æ®å¤„ç†æœ€å¼ºpackage, æ²¡æœ‰ä¹‹ä¸€(? 1 # -*- coding: utf-8 -*- 1 2 3 import pandas as pd import numpy as np import matplotlib.pyplot as plt 1. Series() 1 s = pd.Series([1,3,5,np.nan,6,8]) 1 s 0 1.0 1 3.0 2 5.0 3 NaN 4 6.0 5 8.0</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>pandas</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>PCA</title>
        <link>/blogs/2017-03-27-pca/</link>
        <pubDate>Mon, 27 Mar 2017 16:52:34 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 27 Mar 2017 16:52:34 +0000</atom:modified>
        <guid>/blogs/2017-03-27-pca/</guid>
        <description>å…ˆçœ‹Refer, è¯¥ä»‹ç»çš„éƒ½ä»‹ç»åˆ°ä½äº†: 17/10/09 æ›´æ–°äº†é¢„å¤‡çŸ¥è¯†å’Œè¯¦ç»†è®¡ç®—è¿‡ç¨‹ æœºå™¨å­¦ä¹ ä¸­çš„æ•°å­¦(4)-çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰, ä¸»æˆåˆ†åˆ†æ(PCA) å¼ºå¤§</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>pca</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Logistic Regression, Softmaxä¸æœ€å¤§ç†µ</title>
        <link>/blogs/2017-03-27-logistic-regression/</link>
        <pubDate>Mon, 27 Mar 2017 16:27:20 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 27 Mar 2017 16:27:20 +0000</atom:modified>
        <guid>/blogs/2017-03-27-logistic-regression/</guid>
        <description>Logistic Regressionçš„å°ç»“ ç¬¬ä¸€éƒ¨åˆ† Logistic Regression 1. çº¿æ€§å›å½’çš„ç¼ºç‚¹ çº¿æ€§å›å½’ä¸é€‚ç”¨äºåˆ†ç±»é—®é¢˜: å®¹æ˜“è¿‡æ‹Ÿåˆ $h_\theta$ can be &amp;gt;1 or &amp;lt;0 2. Logisitc Regression 2.1 æ¨¡å‹å‡è®¾ Sigmoidå‡½æ•°:</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>logistic regression</category>
            
          
            
              <category>machine learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>å†³ç­–æ ‘</title>
        <link>/blogs/2017-03-26-decision-tree/</link>
        <pubDate>Mon, 27 Mar 2017 00:29:14 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 27 Mar 2017 00:29:14 +0000</atom:modified>
        <guid>/blogs/2017-03-26-decision-tree/</guid>
        <description>å†³ç­–æ ‘çš„å°ç»“ ç¬¬ä¸€éƒ¨åˆ†: ç†µ, æ¡ä»¶ç†µå’Œä¿¡æ¯å¢ç›Š 1. ç†µ ç†µçš„å®šä¹‰å’Œå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒæœ‰å…³, å’Œå˜é‡æœ¬èº«çš„å€¼æ— å…³, å®šä¹‰å¦‚ä¸‹: $$ H(X) = - \sum\limits_{i=1}^{n} p_i log p_i \\ \text{å…¶ä¸­</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>decision tree</category>
            
          
            
              <category>machine learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Adaboostç®—æ³• &#43; pythonå®ç°</title>
        <link>/blogs/2017-03-24-adaboost/</link>
        <pubDate>Fri, 24 Mar 2017 23:39:40 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 24 Mar 2017 23:39:40 +0000</atom:modified>
        <guid>/blogs/2017-03-24-adaboost/</guid>
        <description>Adaboostçš„æ€»ç»“ ç¬¬ä¸€éƒ¨åˆ†: AdaBoostç®€ä»‹ 1.1 å¼ºå¯å­¦ä¹ å’Œå¼±å¯å­¦ä¹  åœ¨æ¦‚ç‡è¿‘ä¼¼æ­£ç¡®(PAC)å­¦ä¹ æ¡†æ¶ä¸­, ä¸€ä¸ªç±»å¦‚æœå­˜åœ¨: ä¸€ä¸ªå¤šé¡¹å¼å¤æ‚åº¦</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>boosting</category>
            
          
            
              <category>machine learning</category>
            
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>æ”¯æŒå‘é‡æœº(SVM)</title>
        <link>/blogs/2017-03-24-svm-cn/</link>
        <pubDate>Fri, 24 Mar 2017 23:02:02 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 24 Mar 2017 23:02:02 +0000</atom:modified>
        <guid>/blogs/2017-03-24-svm-cn/</guid>
        <description>æ—§æ–‡ç« çš„ç¿»è¯‘, ä¸»è¦å‚è€ƒè‡ªæèˆªçš„ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ä¸€ä¹¦. ç¬¬ä¸€éƒ¨åˆ† åŸºæœ¬æ¦‚å¿µ 1.1 è¶…å¹³é¢(Hyperplane) è€ƒè™‘ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜: $$\text{Training set: } T = \left \lbrace (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}) &amp;hellip;(x^{(N)},</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>SVM</category>
            
          
            
              <category>machine learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>æœ´ç´ è´å¶æ–¯</title>
        <link>/blogs/2017-03-22-naive-bayes/</link>
        <pubDate>Wed, 22 Mar 2017 16:06:07 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 22 Mar 2017 16:06:07 +0000</atom:modified>
        <guid>/blogs/2017-03-22-naive-bayes/</guid>
        <description>æœ´ç´ è´å¶æ–¯(Naive Bayes) å¦‚æ­¤è›¤æ„ç›ç„¶çš„ç®—æ³•, å±…ç„¶ä¸€ç›´æ²¡å†™ åŸç† è®­ç»ƒé›†: $T = \lbrace (X^{(1)}, y_1), (X^{(2)}, y_2), \cdots, (X^{(N)}, y_N) \rbrace$, å…¶ä¸­ $ X = (X_1, X_2, \cdots, X_n), y \in \lbrace c_1, c_2, \cdots, c_K \rbrace $ å­¦ä¹ è¿‡ç¨‹: æ ¹æ®</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>bayes</category>
            
          
            
              <category>machine learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>å­˜æ¡£-æ•°æ®æŒ–æ˜ä½œä¸š</title>
        <link>/blogs/2017-03-18-data-mining-assn1/</link>
        <pubDate>Sat, 18 Mar 2017 11:14:50 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 18 Mar 2017 11:14:50 +0000</atom:modified>
        <guid>/blogs/2017-03-18-data-mining-assn1/</guid>
        <description>USTC Spring 2017: Data Mining Assignment 1 æŒºæœ‰æ„æ€çš„, å­˜åœ¨blogé‡Œå‚è€ƒ, ä»¥åè¯´ä¸å®šç”¨å¾—ä¸Š. ä¸è¿‡è¿™ä¸ªä½œä¸šåº”è¯¥æœ‰ç‚¹å†å²äº†, å‡ºå¤„æœªè€ƒ SA16225220 Question 1 Classify the following attributes as binary, discrete, or continuous. Also classify them as qualitative (nominal or ordinal)</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>nginx &#43; uwsgi &#43; flaskéƒ¨ç½²åº”ç”¨</title>
        <link>/blogs/2017-03-16-nginx-uwsgi-flask/</link>
        <pubDate>Thu, 16 Mar 2017 15:38:14 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 16 Mar 2017 15:38:14 +0000</atom:modified>
        <guid>/blogs/2017-03-16-nginx-uwsgi-flask/</guid>
        <description>ä¸»è¦å‚è€ƒäº†è¿™ç¯‡æ–‡ç«  How To Serve Flask Applications with uWSGI and Nginx on Ubuntu 14.04 å®‰è£…nginx + uwsgi + flask 1 2 sudo apt-get update sudo apt-get install python-pip python-dev nginx å¯åŠ¨virtualenv, ä»¥ä¸‹æ“ä½œéƒ½åœ¨virtuale</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>flask</category>
            
          
            
              <category>nginx</category>
            
          
            
              <category>uwsgi</category>
            
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>scrapy &#43; mongodb &#43; flask &#43; echarts æ•°æ®å¯è§†åŒ–</title>
        <link>/blogs/2017-03-13-mongodb-flask-echarts-data-visualize/</link>
        <pubDate>Mon, 13 Mar 2017 21:33:07 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 13 Mar 2017 21:33:07 +0000</atom:modified>
        <guid>/blogs/2017-03-13-mongodb-flask-echarts-data-visualize/</guid>
        <description>æºç  é¡¹ç›®åœ°å€ é¡¹ç›®æ¡†æ¶ scrapyè´Ÿè´£å®šæ—¶æŠ“å–æ•°æ®åˆ°mongodbä¸­ æ¯å°æ—¶å®šæ—¶ç”Ÿæˆechartséœ€è¦çš„æ•°æ®, ä»¥jsonæ ¼å¼ä¿å­˜ flaskè¯»å–j</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>mongodb</category>
            
          
            
              <category>flask</category>
            
          
            
              <category>echarts</category>
            
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>ä¸€é“é˜¿é‡Œåœ¨çº¿é¢è¯•ç®—æ³•é¢˜--è½å…¥å¿ƒå½¢çº¿çš„æ¦‚ç‡</title>
        <link>/blogs/2017-03-08-online-interview/</link>
        <pubDate>Wed, 08 Mar 2017 18:53:20 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 08 Mar 2017 18:53:20 +0000</atom:modified>
        <guid>/blogs/2017-03-08-online-interview/</guid>
        <description>æœ€è¿‘è¿ç»­è¢«é—®åˆ°ä¸¤ä¸‰æ¬¡, å¯æƒœæ—¶é—´ç´§å¼ æ²¡èƒ½å¸®ä¸Šä»€ä¹ˆå¿™, è¿™é‡Œå°±è®°ä¸€ä¸‹è§£å†³è¿‡ç¨‹å§ å°æ˜å‘ä»–çš„å¥³å‹ä»™ä»™æ±‚å©š, åœ¨æ±‚å©šæˆ’æŒ‡ä¸Šåˆ»äº†ä¸€ä¸ªå¤§å¤§çš„çˆ±å¿ƒ. ä»™ä»™çœ‹åˆ°çˆ±å¿ƒ</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>é¢è¯•é¢˜</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>shadowsocks&#43;chromeä»£ç†é…ç½®é€ŸæŸ¥æ‰‹å†Œ</title>
        <link>/blogs/2017-02-23-shadowsocks-chrome-config/</link>
        <pubDate>Thu, 23 Feb 2017 00:56:07 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 23 Feb 2017 00:56:07 +0000</atom:modified>
        <guid>/blogs/2017-02-23-shadowsocks-chrome-config/</guid>
        <description>æœ€è¿‘è€æ˜¯è¦é…ç½®ss, é¡ºæ‰‹è®°ä¸‹æ¥ä»¥ä¾¿å­˜æ¡£. ä¸ºäº†æ–¹ä¾¿0åŸºç¡€äººå£«é˜…è¯»æå…¶å‚»ç“œ å‚è€ƒå®˜æ–¹æ–‡æ¡£ 1. æœåŠ¡ç«¯(åªæ˜¯ä½¿ç”¨çš„è¯å¯ä»¥è·³è¿‡è¿™èŠ‚ç›´æ¥çœ‹ç¬¬äºŒèŠ‚) 1.1 å®‰è£… apt-get install</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>shadowsocks</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Scrapyç®€ä»‹(é™„é¡¹ç›®:çˆ¬å–å®ä¹ åƒ§å®ä¹ ä¿¡æ¯)</title>
        <link>/blogs/2017-02-18-scrapy/</link>
        <pubDate>Sat, 18 Feb 2017 16:29:59 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 18 Feb 2017 16:29:59 +0000</atom:modified>
        <guid>/blogs/2017-02-18-scrapy/</guid>
        <description>scrapyçš„å®˜æ–¹ä¸­æ–‡æ–‡æ¡£ æºä»£ç  Scrapyæ¡†æ¶æ•°æ®æµ ä¸Šå›¾æ˜¯scrapyçš„æ•°æ®æµ, çœ‹ä¸æ‡‚æ²¡å…³ç³», æ¥ä¸‹æ¥ä¼šç®€å•ä»‹ç»scrapyçˆ¬å–çš„æµç¨‹. 1 2</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>scrapy</category>
            
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>MongoDB&#43;pymongoç®€ä»‹(æŒç»­æ›´æ–°ä¸­)</title>
        <link>/blogs/2017-02-17-mongodb/</link>
        <pubDate>Fri, 17 Feb 2017 16:50:26 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 17 Feb 2017 16:50:26 +0000</atom:modified>
        <guid>/blogs/2017-02-17-mongodb/</guid>
        <description>MongoDB æ˜¯ä¸€ç§æ–‡ä»¶å¯¼å‘çš„ NoSQL æ•°æ®åº“ï¼Œç”± C++ æ’°å†™è€Œæˆã€‚ MongoDBç®€ä»‹ ä»€ä¹ˆæ˜¯NoSQL? çœ‹çœ‹è¿™ç¯‡zhihué—®é¢˜è¶³çŸ£. æˆ‘çš„ç²—æµ…ç†è§£å°±æ˜¯NoSQLå’ŒSQL</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>MongoDB</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>çŸ¥ä¹LIVEæ•´ç†</title>
        <link>/blogs/2017-01-19-encrypted/</link>
        <pubDate>Thu, 19 Jan 2017 20:03:42 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 19 Jan 2017 20:03:42 +0000</atom:modified>
        <guid>/blogs/2017-01-19-encrypted/</guid>
        <description>LIVE1: ä¸€å°æ—¶äº†è§£ä¹³è…ºçš„ç§˜å¯† liveåœ°å€ 1. ç‰ˆæƒæç¤º è®²è€…åœ¨æ­¤liveä¸­å‘è¡¨çš„ä¸€åˆ‡åŸåˆ›å†…å®¹ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºè¯­éŸ³ã€æ–‡å­—ã€å›¾ç‰‡ç­‰ï¼‰çš„è‘—ä½œæƒå‡å½’è®²è€…æ‰€æœ‰ã€‚ä»»ä½•</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>ç®—æ³•æ€»ç»“</title>
        <link>/blogs/2017-01-11-algo-sum/</link>
        <pubDate>Wed, 11 Jan 2017 00:16:02 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 11 Jan 2017 00:16:02 +0000</atom:modified>
        <guid>/blogs/2017-01-11-algo-sum/</guid>
        <description>è¿™æ˜¯ä¸ªè¯¾ç¨‹æ€»ç»“. 1. åˆ†æ²»æ³• é€‚ç”¨æ¡ä»¶ åŸé—®é¢˜å¯ä»¥åˆ†è§£ä¸ºè‹¥å¹²ä¸ªä¸åŸé—®é¢˜æ€§è´¨ç›¸ç±»ä¼¼çš„å­é—®é¢˜ é—®é¢˜çš„è§„æ¨¡ç¼©å°åˆ°ä¸€å®šç¨‹åº¦åå¯æ–¹ä¾¿æ±‚å‡ºè§£ å­é—®é¢˜çš„è§£å¯ä»¥åˆå¹¶å¾—åˆ°</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>2016ç§‹ ç½‘ç»œç¨‹åºè®¾è®¡ è¯¾ç¨‹å­¦ä¹ å¿ƒå¾—æ€»ç»“</title>
        <link>/blogs/2017-01-05-np2016/</link>
        <pubDate>Thu, 05 Jan 2017 20:24:27 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 05 Jan 2017 20:24:27 +0000</atom:modified>
        <guid>/blogs/2017-01-05-np2016/</guid>
        <description>è¿™æ˜¯ä¸ªè¯¾ç¨‹æŠ¥å‘Š 1. è¯¾ç¨‹è´¡çŒ®: pull requests(2æ¬¡) #æ›´æ–°é¡¹ç›®1æ‰‹å†™ä½“è¯†åˆ«çš„README #221 sklearnæ”¹è¿› å°†æ•°æ®é›†æ›´æ¢ä¸ºtrain2.cs</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
        
        
      </item>
      
      <item>
        <title>Blazing Fast! ä½¿ç”¨YOLO&#43;Darknetè¿›è¡Œç›®æ ‡æ£€æµ‹</title>
        <link>/blogs/2016-12-26-yolo-darknet/</link>
        <pubDate>Mon, 26 Dec 2016 15:15:08 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 26 Dec 2016 15:15:08 +0000</atom:modified>
        <guid>/blogs/2016-12-26-yolo-darknet/</guid>
        <description>YOLOåšç›®æ ‡æ£€æµ‹å¾ˆå¿« ç³»ç»Ÿé…ç½® ç³»ç»Ÿ: Ubuntu 16.04 x64 æ˜¾å¡: gtx960m + i5æ ¸æ˜¾ å†…å­˜: 8G CPU: i5-6300HQ ä½¿ç”¨ç‹¬ç«‹æ˜¾å¡ å®‰è£…é©±åŠ¨å’Œåˆ‡æ¢å·¥å…· sudo apt-get install nvidia-364 nvidia-prime é©±åŠ¨ç‰ˆæœ¬å¯ä»¥åˆ°è½¯ä»¶æ›´æ–°-&amp;g</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>deep learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Github Page &#43; Hexo &#43; nextä¸»é¢˜ blogç½‘ç«™çš„æ­å»º</title>
        <link>/blogs/2016-12-22-hexo-blog-based-on-next-theme/</link>
        <pubDate>Thu, 22 Dec 2016 15:40:00 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 22 Dec 2016 15:40:00 +0000</atom:modified>
        <guid>/blogs/2016-12-22-hexo-blog-based-on-next-theme/</guid>
        <description>ç®€å•ä»‹ç»ä¸€ä¸‹æœ¬ç«™çš„å»ºç«‹è¿‡ç¨‹ éƒ¨ç½²Hexo ç³»ç»Ÿ: Ubuntu 16.04 LTS 0. å®‰è£…Git(ç•¥) 1. å®‰è£… Node.js æœ€å¥½ä½¿ç”¨nvmæ¥å®‰è£…Node.js æ–¹æ³•ä¸€: cURL: $ curl https://raw.githubusercontent.com/creationix/nvm/master/install.sh | sh æ–¹æ³•äºŒ: Wget:</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>blog</category>
            
          
            
              <category>hexo</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Jupyter Notebooks ç®€ä»‹</title>
        <link>/blogs/2016-12-22-jupyter-notebooks/</link>
        <pubDate>Thu, 22 Dec 2016 15:37:15 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 22 Dec 2016 15:37:15 +0000</atom:modified>
        <guid>/blogs/2016-12-22-jupyter-notebooks/</guid>
        <description>jupyterå¯ä»¥çœ‹ä½œæ˜¯ä¸€æ¬¾å¼ºåŒ–ç‰ˆçš„python terminal, å®æ—¶è¿è¡Œå‘½ä»¤è„šæœ¬, å®æ—¶åæ˜ ç»“æœ, éå¸¸é€‚ç”¨äºç§‘å­¦è®¡ç®—å’Œæ•°æ®åˆ†æ. é™¤æ­¤ä¹‹å¤–é€šè¿‡å®‰è£…kernel</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>åŸºäºDockerçš„Faster R-CNN, CPU-Onlyç¯å¢ƒé…ç½®</title>
        <link>/blogs/2016-12-10-build-fast-rcnn-under-docker/</link>
        <pubDate>Sat, 10 Dec 2016 19:24:42 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 10 Dec 2016 19:24:42 +0000</atom:modified>
        <guid>/blogs/2016-12-10-build-fast-rcnn-under-docker/</guid>
        <description>è¯¦è§æˆ‘çš„repo 1. ç³»ç»Ÿé…ç½® ç³»ç»Ÿ: VMwareä¸‹çš„Ubuntu 14.04 LTS x64, éœ€è¦åˆ†é…è‡³å°‘4GBå†…å­˜ å‘: å†…å­˜è¿‡å°(&amp;lt;1G)ç¼–è¯‘æ—¶ä¼šå‡ºé”™: g++: internal compiler error: Killed</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>docker</category>
            
          
            
              <category>deep learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Dockeré€ŸæŸ¥</title>
        <link>/blogs/2016-12-06-docker-abc/</link>
        <pubDate>Thu, 08 Dec 2016 19:29:07 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 08 Dec 2016 19:29:07 +0000</atom:modified>
        <guid>/blogs/2016-12-06-docker-abc/</guid>
        <description>dockeræ˜¯ä¸€æ¬¾å¾ˆç‰›é€¼çš„è™šæ‹ŸåŒ–å·¥å…· 1. å®‰è£… è¦æ±‚ 64ä½ç³»ç»Ÿ kernelç‰ˆæœ¬ä¸º3.10æˆ–ä»¥ä¸Š ä»¥ä¸‹ä½¿ç”¨çš„æ˜¯Ubuntu 14.04 LTS 64ä½ å‚è€ƒå®˜æ–¹æ–‡æ¡£ 2. ä½¿ç”¨</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>docker</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Landslide - Markdown to Slide</title>
        <link>/blogs/2016-11-25-landslide/</link>
        <pubDate>Fri, 25 Nov 2016 11:24:20 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 25 Nov 2016 11:24:20 +0000</atom:modified>
        <guid>/blogs/2016-11-25-landslide/</guid>
        <description>Landslide æ˜¯ä¸ªå¯ä»¥æŠŠmarkdownæ–‡ä»¶å˜æˆå¹»ç¯ç‰‡ç›´æ¥åœ¨æµè§ˆå™¨é‡Œæ’­æ”¾çš„å·¥å…·. é¡µé¢ä¹‹é—´ç›´æ¥ä½¿ç”¨---é—´éš”å³å¯ ç¯å¢ƒé…ç½® 1 2 3 4 5 6 pip install -U markdown pip install -U docutils pip install Jinja2</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>markdown</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>git ä»forkçš„é¡¹ç›®æ›´æ–°è‡ªå·±çš„é¡¹ç›®çš„ç®€æ˜“æ‰‹æ®µ</title>
        <link>/blogs/2016-11-22-git-update-forked/</link>
        <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 22 Nov 2016 00:00:00 +0000</atom:modified>
        <guid>/blogs/2016-11-22-git-update-forked/</guid>
        <description>RT å‡è®¾ç™½äº•é»‘å­ä»[misaki/railgun.git]å¤„forkäº†ç‚®å§çš„é¡¹ç›®åˆ°è‡ªå·±çš„é¡¹ç›®[kuroko/railgun.git] è¿‡äº†æ®µæ—¶é—´</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>git</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>åœ¨mac os 10.12 Sierraä¸‹å®‰è£…caffe</title>
        <link>/blogs/2016-11-12-install-caffe-under-macos/</link>
        <pubDate>Sat, 12 Nov 2016 16:34:06 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 12 Nov 2016 16:34:06 +0000</atom:modified>
        <guid>/blogs/2016-11-12-install-caffe-under-macos/</guid>
        <description>RT 1. é…ç½® Mac OS Sierra 10.12.1 2. å®‰è£… å®‰è£…CUDA8 (ç•¥) 1 2 3 brew install -vd snappy leveldb gflags glog szip lmdb brew tap homebrew/science brew install hdf5 opencv brew edit opencv, æ”¹å˜å¦‚ä¸‹ä¸¤è¡Œ: 1 2 -DPYTHON_LIBRARY=#{py_prefix}/lib/libpython2.7.dylib -DPYTHON_INCLUDE_DIR=#{py_prefix}/include/python2.7 å®‰è£…protobufå’Œboost</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>caffe</category>
            
          
            
              <category>deep learning</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>EMç®—æ³•</title>
        <link>/blogs/2016-08-26-expectation-maximization/</link>
        <pubDate>Fri, 26 Aug 2016 21:01:12 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 26 Aug 2016 21:01:12 +0000</atom:modified>
        <guid>/blogs/2016-08-26-expectation-maximization/</guid>
        <description>Expectation Maximization Algorithm 1. ä¸‰ç¡¬å¸æ¨¡å‹ å‡è®¾æœ‰ä¸‰æšç¡¬å¸A, B, C, è¿™äº›ç¡¬å¸æ­£é¢å‡ºç°çš„æ¦‚ç‡æ˜¯$p_a$, $p_b$, $p_c$. è¿›è¡Œå¦‚ä¸‹æ·ç¡¬å¸è¯•éªŒ: æ·ç¡¬å¸A è‹¥Aä¸ºæ­£é¢åˆ™é€‰æ‹©B, å¦åˆ™é€‰æ‹©C æ·</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>EMç®—æ³•</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>bilibiliæ–°ç•ª/æ—§ç•ªå¼¹å¹•æŠ“å–</title>
        <link>/blogs/2016-07-17-bilibili-scraper/</link>
        <pubDate>Sun, 17 Jul 2016 20:09:38 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sun, 17 Jul 2016 20:09:38 +0000</atom:modified>
        <guid>/blogs/2016-07-17-bilibili-scraper/</guid>
        <description>ä¸»è¦æ¶‰åŠåˆ°Seleniumçš„ä½¿ç”¨ æºä»£ç : https://github.com/shawnau/bilibili_scraper æœ¬æ–‡ä¸­çš„æ‰€æœ‰æŠ€æœ¯åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­å‡æœ‰ä»‹ç», å› æ­¤æœ¬æ–‡åªæ¶‰åŠåˆ°é’ˆå¯¹bilibiliä¸»é¡µç»“æ„çš„åˆ†æ, çœç•¥äº†</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
            
              <category>çˆ¬è™«</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>åŸºäºselenium&#43;phantomJSçš„åŠ¨æ€ç½‘é¡µæŠ“å–</title>
        <link>/blogs/2016-07-16-webscraper/</link>
        <pubDate>Sat, 16 Jul 2016 12:26:35 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 16 Jul 2016 12:26:35 +0000</atom:modified>
        <guid>/blogs/2016-07-16-webscraper/</guid>
        <description>æºä»£ç : https://github.com/shawnau/ustcsse_scraper 0. å‡†å¤‡å·¥ä½œ é¦–å…ˆä»‹ç»ä¸‹éœ€è¦å®‰è£…çš„ç»„ä»¶ï¼š selenium, è‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…·, æœ¬æ–‡ä¼šé€šè¿‡å®ƒæ“çºµphantomJS, ä½¿å¾—çˆ¬è™«èƒ½åšå‡ºæ¨¡ä»¿æ™®é€šç”¨æˆ·çš„æ“ä½œ, åŸºäºp</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>python</category>
            
          
            
              <category>çˆ¬è™«</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Spark Tutorial - Learning Apache Spark</title>
        <link>/blogs/2016-06-28-spark-tutorial/</link>
        <pubDate>Tue, 28 Jun 2016 04:15:50 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 28 Jun 2016 04:15:50 +0000</atom:modified>
        <guid>/blogs/2016-06-28-spark-tutorial/</guid>
        <description>Sparkç®€ä»‹ This article is copied from the BerkeleyX: CS105x Introduction to Apache Spark course materials. Source: https://raw.githubusercontent.com/spark-mooc/mooc-setup/master/cs105_lab1a_spark_tutorial.dbc This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. Spark Tutorial: Learning Apache Spark This tutorial will teach you how to use Apache Spark, a framework for large-scale data processing, within a notebook. Many traditional frameworks were designed to be run on a single</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>spark</category>
            
          
            
              <category>CS105x</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Boosting(3)- Gradient Boosting</title>
        <link>/blogs/2016-06-24-gradient-boosting/</link>
        <pubDate>Thu, 23 Jun 2016 22:47:00 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 23 Jun 2016 22:47:00 +0000</atom:modified>
        <guid>/blogs/2016-06-24-gradient-boosting/</guid>
        <description>æ¢¯åº¦æå‡ç®—æ³•ç®€ä»‹ Boosting on different Loss Functions In the last section, we use forward stagewise on an addictive model to solve the optimization of adaboost. The exponential loss function is relatively easy to handle, but other loss functions may not. Recall from the last section, we have loss function like this: $$ L(y_i, f(x_i)) $$ Consider optimizing an arbitary loss function using forward stagewise:</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
            
              <category>boosting</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Boosting(2) - Adaboost and Forward Stagewise</title>
        <link>/blogs/2016-06-22-forward-stagewise-algorithm/</link>
        <pubDate>Wed, 22 Jun 2016 06:30:37 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 22 Jun 2016 06:30:37 +0000</atom:modified>
        <guid>/blogs/2016-06-22-forward-stagewise-algorithm/</guid>
        <description>Boostingç†è®ºåŸºç¡€: å’Œå‰å‘åˆ†æ­¥ç®—æ³•çš„ç­‰ä»·æ€§ Forward stagewise Consider an additive model like adaboost: $$ f(x) = \sum\limits_{m=1}^M \beta_m b(x; \gamma_m) $$ in which $b(x; \gamma_m)$ is the base model, $\gamma_m$ is the model&amp;rsquo;s parameters, $\beta_m$ is it&amp;rsquo;s coefficient. To minimim the loss function, we have the forward stagewise algorithm, which minimize</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
            
              <category>boosting</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>SQL é€ŸæŸ¥</title>
        <link>/blogs/2016-06-20-sql-abc/</link>
        <pubDate>Sun, 19 Jun 2016 07:51:31 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sun, 19 Jun 2016 07:51:31 +0000</atom:modified>
        <guid>/blogs/2016-06-20-sql-abc/</guid>
        <description>All the resources from codecademy Basic Operations celebs: $$ \begin{array}{c|c|c|c} \text{id} &amp;amp; \text{name} &amp;amp; \text{age} &amp;amp; \text{twitter_handle} \\ \hline 1 &amp;amp; \text{Justin Bieber} &amp;amp; 22 &amp;amp; \\ 2 &amp;amp; \text{Beyonce Knowles} &amp;amp; 33 &amp;amp; \\ 3 &amp;amp; \text{Jeremy Lin} &amp;amp; 26 &amp;amp; \\ \end{array} $$ Table Creation CREATE TABLE celebs (id INTEGER, name TEXT, age INTEGER, twitter_handle TEXT); Changing values UPDATE celebs SET age = 22 WHERE id = 1;</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>SQL</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Boosting(1) - AdaBoost</title>
        <link>/blogs/2016-06-06-adaboost/</link>
        <pubDate>Mon, 06 Jun 2016 06:50:16 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 06 Jun 2016 06:50:16 +0000</atom:modified>
        <guid>/blogs/2016-06-06-adaboost/</guid>
        <description>Adaptive Boosting ç®—æ³• Combine different classifiers &amp;amp; weights Test data: $$T = \left\lbrace (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(N)}, y^{(N)})\right\rbrace, \quad x \in \chi \subseteq R^N, y \in \lbrace +1, -1 \rbrace \\ \text{with weights: } D_i = (w_{i1}, w_{i2}, \cdots, w_{iN})$$ Classifier: $$G_m(x): \chi \to \lbrace +1, -1\rbrace, \quad G(x) = \sum\limits^M_{i=1} \alpha_m G_m(x) \\ \text{with weights: } A = (\alpha_{1}, \alpha_{2}, \cdots, \alpha_{M}) $$ AdaBoost Algorithm Input:</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>boosting</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Decision Tree</title>
        <link>/blogs/2016-05-22-decision-tree/</link>
        <pubDate>Sun, 22 May 2016 07:41:08 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sun, 22 May 2016 07:41:08 +0000</atom:modified>
        <guid>/blogs/2016-05-22-decision-tree/</guid>
        <description>å†³ç­–æ ‘ CN ver. 1. ç†µ ç†µçš„å®šä¹‰å’Œå˜é‡çš„æ¦‚ç‡åˆ†å¸ƒæœ‰å…³, å’Œå˜é‡æœ¬èº«çš„å€¼æ— å…³, å®šä¹‰å¦‚ä¸‹: $$ H(X) = - \sum\limits_{i=1}^{n} p_i log p_i \\ \text{å…¶ä¸­} P(X=x_i) = p_i, i= 1,2,\cdots, n$$ $H(X)$çš„ä¸€ä¸ª</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>decision tree</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Support Vector Machine(4)-SMO implementation</title>
        <link>/blogs/2016-05-16-smo-implementation/</link>
        <pubDate>Mon, 16 May 2016 07:41:08 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 16 May 2016 07:41:08 +0000</atom:modified>
        <guid>/blogs/2016-05-16-smo-implementation/</guid>
        <description>SMOç®—æ³•çš„pythonå®ç° Full implementation here SMO.1: Calculating $L$, $H$ and $E_i$ if p.y[i] != p.y[j]: L = max(0, p.a[j] - p.a[i]) H = min(p.c, p.a[j] - p.a[i] + p.c) else: L = max(0, p.a[j] + p.a[i] - p.c) H = min(p.c, p.a[j] + p.a[i]) def calc_ei(p, i): f_xi = float(np.dot((p.a * p.y).T, np.dot(p.x, p.x[i].T)) + p.b) ei =</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>svm</category>
            
          
            
              <category>machine-learning-in-action</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Support Vector Machine(3)-SMO</title>
        <link>/blogs/2016-05-14-smo/</link>
        <pubDate>Sat, 14 May 2016 13:33:33 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 14 May 2016 13:33:33 +0000</atom:modified>
        <guid>/blogs/2016-05-14-smo/</guid>
        <description>åºåˆ—æœ€å°åŒ–ç®—æ³• Recall from the last section: $ \begin{align} &amp;amp; \min\limits_{\alpha} \quad \frac{1}{2} \sum\limits_{i=1}^{N} \sum\limits_{j=1}^{N} \alpha_i \alpha_j y^{(i)} y^{(j)} K(x^{(i)}, x^{(j)}) - \sum\limits_{i=1}^{N} \alpha_i \end{align} \tag{3.2}$ $ s.t. \quad \sum\limits_{i=1}^{N} \alpha_i y^{(i)} = 0, \quad 0 \le \alpha_i \le C \tag{3.4}$ To solve the optimization problem above, we introduce the Sequantial Minimal Optimization(SMO) method. Solve the 2-variable Quadratic Programming Assume from all of the $\alpha_i$,</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>svm</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Support Vector Machine(2.2)-Solving dual problem for soft margin maximization</title>
        <link>/blogs/2016-05-12-svm2_2/</link>
        <pubDate>Thu, 12 May 2016 13:33:33 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 12 May 2016 13:33:33 +0000</atom:modified>
        <guid>/blogs/2016-05-12-svm2_2/</guid>
        <description>SVMä¹‹è½¯é—´éš”æœ€å¤§åŒ– Recall from the 1st section, we have: $$ \begin{align} &amp;amp; \min\limits_{w, \xi} \quad \frac{1}{2} {\Vert w \Vert}^2 + C \sum\limits_{i=1}^{N}\xi_i \\ s.t. \quad &amp;amp; y^{(i)} \left ( w \cdot x^{(i)} + {b} \right ) + \xi_i - 1\ge 0 \ &amp;amp; \xi_i \ge 0\tag{1.10} \end{align}$$ For the constraint condition and target function in (1.10), using the method of Lagrange multipliers,</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>svm</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Support Vector Machine(2.1)-Solving dual problem for hard margin maximization</title>
        <link>/blogs/2016-05-12-svm2_1/</link>
        <pubDate>Thu, 12 May 2016 06:57:41 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 12 May 2016 06:57:41 +0000</atom:modified>
        <guid>/blogs/2016-05-12-svm2_1/</guid>
        <description>SVMä¹‹ç¡¬é—´éš”æœ€å¤§åŒ– In the last section, (1.8) is a convex quadratic programming problem. Using the method of Lagrange multipliers, (1.8) could be represented as: $$ L(w,b,\alpha) = \frac{1}{2} {\Vert w \Vert}^2 + \sum\limits_{i=1}^{N} \alpha_i (1-y^{(i)}(w \cdot x^{(i)} + b)), \alpha_i \ge 0 \tag{2.1}$$ The dual problem is: $$\max\limits_{\alpha} \ \min\limits_{w,b} L(w,b,\alpha) \tag{2.2}$$ Solving $\min\limits_{w,b} L(w,b,\alpha)$ $$ \nabla_w L(w,b,\alpha) = w - \sum\limits_{i=1}^{N}</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>svm</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Support Vector Machine(1) - Hard margin maximization</title>
        <link>/blogs/2016-05-11-svm/</link>
        <pubDate>Wed, 11 May 2016 15:36:18 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Wed, 11 May 2016 15:36:18 +0000</atom:modified>
        <guid>/blogs/2016-05-11-svm/</guid>
        <description>æ”¯æŒå‘é‡æœº Hyperplane Consider a two-class separation problem: $$\text{Training set: } T = \left \lbrace (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}) &amp;hellip;(x^{(N)}, y^{(N)}) \right \rbrace \\ \text{in which }x^{(i)} \in R^n, y^{(i)} \in \lbrace +1, -1 \rbrace, i=1,2&amp;hellip;N$$ Assuming all the samples in the sample space X are linearly separable, we have the hyperplane: $$ w \cdot x + b = 0 \text{, in which }w, b \in R^N$$</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>svm</category>
            
          
            
              <category>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(13)-Programming Exercise 5</title>
        <link>/blogs/2016-02-27-programming-exercise-5/</link>
        <pubDate>Sat, 27 Feb 2016 22:17:15 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 27 Feb 2016 22:17:15 +0000</atom:modified>
        <guid>/blogs/2016-02-27-programming-exercise-5/</guid>
        <description>Programming Exercise 5
Notification: This is a simplified code example, if you are attempting this class, don&amp;rsquo;t copy &amp;amp; submit since it won&amp;rsquo;t even work&amp;hellip;
Regularized linear regression 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 function [J, grad] = linearRegCostFunction(X, y, theta, lambda) % Initialize some useful values m = length(y); % number of training examples n = size(theta,1); % You need to return the following variables correctly J = 0; grad = zeros(size(theta)); % Calculate cost function J = (1/(2*m))*sum((X*theta .</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(12)-Advice for Applying Machine Learning</title>
        <link>/blogs/2016-02-27-advice-for-applying-machine-learning/</link>
        <pubDate>Sat, 27 Feb 2016 22:10:17 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 27 Feb 2016 22:10:17 +0000</atom:modified>
        <guid>/blogs/2016-02-27-advice-for-applying-machine-learning/</guid>
        <description>Advice for Applying Machine Learning
Debugging a learning algorithm Get more training data Try smaller sets of features Getting additional features Changing fit hypothesis Changing $\lambda$ Evaluate hypothesis Training/testing procedure Splitting data into training set and test set Learn parameters from training data Compute test error If $J_{train}(\theta)$ is low while $J_{test}(\theta)$ is high, then it might be overfitting. For logistic regression Misclassification error:
$$
err(h_\theta (x), y) =
\begin{cases}</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(11)-Programming Exercise 4</title>
        <link>/blogs/2016-02-20-programming-exercise-4/</link>
        <pubDate>Sat, 20 Feb 2016 14:37:56 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 20 Feb 2016 14:37:56 +0000</atom:modified>
        <guid>/blogs/2016-02-20-programming-exercise-4/</guid>
        <description>Programming Exercise 4
Notification: This is a simplified code example, if you are attempting this class, don&amp;rsquo;t copy &amp;amp; submit since it won&amp;rsquo;t even work&amp;hellip;
Cost function for fmincg 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 function [J grad] = nnCostFunction(nn_params, .</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(10)-Neural Networks Learning</title>
        <link>/blogs/2016-02-20-neural-networks-learning/</link>
        <pubDate>Sat, 20 Feb 2016 13:55:02 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 20 Feb 2016 13:55:02 +0000</atom:modified>
        <guid>/blogs/2016-02-20-neural-networks-learning/</guid>
        <description>Neural Networks Learning
Cost Fuction 1. For a neural network like the pic above, the cost function should be like: $$ J(\theta) = \frac {1}{m} \sum\limits\_{i=1}^{m}\sum\limits\_{k=1}^{K} [-y\_k^{(i)} log(h\_\theta (x^{(i)})\_k) - (1 - y\_k^{(i)}) log(1 - h\_\theta (x^{(i)})\_k)] $$ 2. In which there are m training data and the output layer has K units. The cost function will sum all the outputs from all the data. 3. Similarly, the regularization term just sum up the square of all the parameters from all the layers: $$ \frac {\lambda}{2m} \sum\limits\_{j=1}^{s^{(l)}} \sum\limits\_{k=2}^{s^{(l+1)}} \sum\limits\_{l=1}^{n} [(\Theta\_{jk}^{(l)})^2] $$ 4.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>neural network</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(8)-Neural Networks Representation</title>
        <link>/blogs/2016-02-11-neural-networks-representation/</link>
        <pubDate>Thu, 11 Feb 2016 16:38:03 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Thu, 11 Feb 2016 16:38:03 +0000</atom:modified>
        <guid>/blogs/2016-02-11-neural-networks-representation/</guid>
        <description>Neural Networks Model A single neuron model: logistic unit - Takes 3+1 inputs(the extra input called bias is just like $\theta\_0$ in logistic regression, not shown in picture). - Both input and output could be represented as vectors, in which each unit has its own parameters $\theta$ - All the units in the same layer take the same input $\mathbf{x}$, as the pic shows. - Each unit has only one output: $sigmoid(\theta^T x)$.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>neural network</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(7)-Programming Exercise 2</title>
        <link>/blogs/2016-02-09-programming-exercise-2/</link>
        <pubDate>Tue, 09 Feb 2016 19:59:32 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 09 Feb 2016 19:59:32 +0000</atom:modified>
        <guid>/blogs/2016-02-09-programming-exercise-2/</guid>
        <description>Programming Exercise 2
Notification: This is a simplified code example, if you are attempting this class, don&amp;rsquo;t copy &amp;amp; submit since it won&amp;rsquo;t even work&amp;hellip;
Plot function 1 2 3 4 5 6 7 8 9 10 11 12 13 function plotData(X, y) figure; hold on; pos = find(y==1); neg = find(y == 0); plot(X(pos, 1), X(pos, 2), &amp;#39;k+&amp;#39;,&amp;#39;LineWidth&amp;#39;, 2, ... &amp;#39;MarkerSize&amp;#39;, 7); plot(X(neg, 1), X(neg, 2), &amp;#39;ko&amp;#39;, &amp;#39;MarkerFaceColor&amp;#39;, &amp;#39;y&amp;#39;, .</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(9)-Programming Exercise 3</title>
        <link>/blogs/2016-02-13-programming-exercise-3/</link>
        <pubDate>Tue, 09 Feb 2016 19:59:32 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Tue, 09 Feb 2016 19:59:32 +0000</atom:modified>
        <guid>/blogs/2016-02-13-programming-exercise-3/</guid>
        <description>Programming Exercise 3
Multi-class Classification CostFunction for fmincg 1 2 3 4 5 6 7 8 9 10 11 12 function [J, grad] = lrCostFunction(theta, X, y, lambda) % Initialize some useful values m = length(y); % number of training examples n = size(theta,1); J = (1/m)*sum(-y .* log(sigmoid(X*theta)) - (1 .- y) .* log(1 .- sigmoid(X*theta))) + (lambda/(2*m))*(theta&amp;#39;(2:n) * theta(2:n)); grad(1) = ((X&amp;#39;)*(sigmoid(X*theta) - y)*(1/m))(1); grad(2:n,:) = ((X&amp;#39;)*(sigmoid(X*theta) - y)*(1/m) + (lambda/m)*theta)(2:n,:); end The same as is in Programming Exercise 2 One-vs-all Classification 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 function [all_theta] = oneVsAll(X, y, num_labels, lambda) % Some useful variables m = size(X, 1); n = size(X, 2); % Initialize X and all_theta X = [ones(m, 1) X]; all_theta = zeros(num_labels, n + 1); % Initialize options for fmincg initial_theta = zeros(n + 1, 1); options = optimset(&amp;#39;GradObj&amp;#39;, &amp;#39;on&amp;#39;, &amp;#39;MaxIter&amp;#39;, 50); % Generate rows of all_theta row by row using fmincg for iter = 1:num_labels all_theta(iter,:) = (fmincg (@(t)(lrCostFunction(t, X, (y == iter), lambda)), initial_theta, options))&amp;#39;; end; end ONEVSALL trains multiple logistic regression classifiers and returns all the classifiers in a matrix all_theta, where the i-th row of all_theta corresponds to the classifier for label i The parameter y == iter returns a vector of the same size as y with ones at positions where the elements of y are equal to iter and zeroes where they are different.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(6)-Logistic Regression</title>
        <link>/blogs/2016-02-06-logistic-regression/</link>
        <pubDate>Sat, 06 Feb 2016 18:54:52 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 06 Feb 2016 18:54:52 +0000</atom:modified>
        <guid>/blogs/2016-02-06-logistic-regression/</guid>
        <description>Logistic Regression
Linear Regression is not suitable for classification problem overfit $h_\theta$ can be &amp;gt;1 or &amp;lt;0 Logisitc Regression Hypothesis Representation Sigmoid/Logistic Function for linear regression: $$h_\theta (x) = \frac {1}{1 + e^{-\theta^T x}}$$ Interpretation: estimated probability that y=1 on input x $P(y=0|x=\theta) + P(y=1|x=\theta) = 1$ Decision Boundary Linear Regression: y=1 equals to $\theta^T x$ &amp;gt; 0 which is decided by parameters Unlinear Regression: Polynomial Regression etc. Cost function for one variable hypothesis To let the cost function be convex for gradient descent, it should be like this:</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>logistic regression</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(5)-Programming Exercise 1</title>
        <link>/blogs/2016-02-01-programming-exercise-1/</link>
        <pubDate>Mon, 01 Feb 2016 16:13:57 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 01 Feb 2016 16:13:57 +0000</atom:modified>
        <guid>/blogs/2016-02-01-programming-exercise-1/</guid>
        <description>Programming Exercise 1: Gradient Descent for Linear regression
Gradient Descent for Linear regression Notification: This is a simplified code example, if you are attempting this class, don&amp;rsquo;t copy &amp;amp; submit since it won&amp;rsquo;t even work&amp;hellip;
Step 1 - Load &amp;amp; Initialize Data 1 2 3 4 5 6 7 data = load(&amp;#39;ex1data1.txt&amp;#39;); X = data(:, 1); y = data(:, 2); X = [ones(m, 1), data(:,1)]; theta = zeros(2, 1); iterations = 1500; alpha = 0.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(4)-Octave abc</title>
        <link>/blogs/2016-02-01-octave-abc/</link>
        <pubDate>Mon, 01 Feb 2016 13:44:34 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Mon, 01 Feb 2016 13:44:34 +0000</atom:modified>
        <guid>/blogs/2016-02-01-octave-abc/</guid>
        <description>Too lazy to explain some of the commands&amp;hellip;orz
Basic PS1(&#39;sign&#39;) Change prompt to &amp;lsquo;sign&amp;rsquo; Matrix Assignment v = [1 2; 3 4; 5 6] v = [1.1 1.2 1.3] = [1:&amp;lt;0.1:&amp;gt;1.3] (default step is 1) Matrix Generation commands ones(2,3) = [1 1 1; 1 1 1] (ones/zeros/rand/randn) eye(n): generate n by n identical matrix magic(n): generate n by n magic matrix size(M, n): return the size of the n=1:row n=2:coloum length(M): max dimention of M Moving data around pwd: show current path load(&#39;xxx&#39;) load &amp;lt;filename&amp;gt; who: display current scope.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(3)-Multivariate Linear Regression</title>
        <link>/blogs/2016-01-30-multivariate-linear-regression/</link>
        <pubDate>Sat, 30 Jan 2016 16:20:23 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Sat, 30 Jan 2016 16:20:23 +0000</atom:modified>
        <guid>/blogs/2016-01-30-multivariate-linear-regression/</guid>
        <description>Multivariate Linear Regression
Gradient Descent for Multiple Variables Suppose we have n variables, set hypothesis to be:
$$h_\theta(\mathbf{x}) = \sum_{i=0}^n \theta_i x_i = \theta^T \mathbf{x}, x_0 =1$$
in which $\mathbf{x} = \begin{bmatrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}$, $\mathbf{\theta} = \begin{bmatrix}\theta_1 \\ \theta_2 \\ \vdots \\ \theta_n \end{bmatrix}$
Cost Function
$$J(\theta^T) = \frac {1}{2m} \sum_{i=1}^m (h_\theta (\mathbf{x}^{(i)}) - y^{(i)} )^2$$
Gredient Descent Algorithm
$$\begin{align*} \text{repeat until convergence: } \lbrace &amp;amp; \\ \theta_j := &amp;amp; \theta_j - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}\left((h_\theta(\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)}\right) \ \rbrace&amp;amp;\end{align*}$$</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>linear regression</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(2)-A Linear Regression Example</title>
        <link>/blogs/2016-01-29-model-and-cost-function/</link>
        <pubDate>Fri, 29 Jan 2016 22:38:43 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 29 Jan 2016 22:38:43 +0000</atom:modified>
        <guid>/blogs/2016-01-29-model-and-cost-function/</guid>
        <description>This is my notes for the open course Machine Learning from coursera.
Model and Cost Function - A Linear Regression Example Hypothesis: $$h_\theta(x) = \theta_0 + {\theta_1}x$$ Cost function: $$J(\theta_0, \theta_1) = \frac {1}{2m} \sum_{i=1}^m (h_\theta (x^{(i)}) - y^{(i)} )^2$$ Basically this function is derived from the maximum likelihood estimation of a set of $\theta_a, \theta_b \sim N(0, \sigma^2)$ $\exists J(\theta_a, \theta_b) (J(\theta_a, \theta_b) = min \lbrace J(\theta_0, \theta_1) \rbrace ) \to \theta_a, \theta_b$ is the best fit of hypothesis Parameter Learning - Minimize Cost Function Gradient descent algorithm repeat until convergence:$$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)$$ Notifications $\alpha$: learning rate.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Machine Learning Notes(1)-Supervised and Unsupervised Learning</title>
        <link>/blogs/2016-01-29-supervised-learning/</link>
        <pubDate>Fri, 29 Jan 2016 16:47:34 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 29 Jan 2016 16:47:34 +0000</atom:modified>
        <guid>/blogs/2016-01-29-supervised-learning/</guid>
        <description>This is my notes for the open course Machine Learning from coursera.
Supervised learning Model given a set of data assigned with special features(experience) build a model through learning algorithm(task) predict the features through given data using the model built(performance) Regression problem predict through consecutive data Classification problem pretict between discrete data sets learning from multiple(even infinite) featurea as parameters Unsupervised learning Model given a set of data(with no features) build a model through learning algorithm like cluster, etc.</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>machine learning</category>
            
          
            
              <category>coursera</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>åˆ©ç”¨é“¾è¡¨ADTå­¦ä¹ C&#43;&#43;é¢å‘å¯¹è±¡(2) - æ ˆå’Œé˜Ÿåˆ—ç»§æ‰¿é“¾è¡¨</title>
        <link>/blogs/2016-01-22-cpp-fundamental-2/</link>
        <pubDate>Fri, 22 Jan 2016 20:03:27 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 22 Jan 2016 20:03:27 +0000</atom:modified>
        <guid>/blogs/2016-01-22-cpp-fundamental-2/</guid>
        <description>some cpp fundamentals æ ˆ #include &amp;lt;iostream&amp;gt; #include &amp;#34;LinkedList_simplified.h&amp;#34; using namespace std; template &amp;lt;typename T&amp;gt; class xStack : public LinkedList&amp;lt;T&amp;gt; //don&amp;#39;t miss &amp;lt;T&amp;gt; here { public: T&amp;amp; gettop() {return LinkedList&amp;lt;T&amp;gt;::begin();} void push(T rhs) {LinkedList&amp;lt;T&amp;gt;::insert(0, rhs);} bool pop(T&amp;amp; popout) { if (LinkedList&amp;lt;T&amp;gt;::size() == 1) { cout &amp;lt;&amp;lt; &amp;#34;error:Already Empty&amp;#34; &amp;lt;&amp;lt; endl; return false; } else { popout = LinkedList&amp;lt;T&amp;gt;::begin(); LinkedList&amp;lt;T&amp;gt;::erase(1); return true; } } }; æ ˆçš„å®ç°æ˜¯é€šè¿‡</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>cpp</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>åˆ©ç”¨é“¾è¡¨ADTå­¦ä¹ C&#43;&#43;é¢å‘å¯¹è±¡(1) - åŸºç¡€çŸ¥è¯†</title>
        <link>/blogs/2016-01-22-cpp-fundamental-1/</link>
        <pubDate>Fri, 22 Jan 2016 17:35:14 +0000</pubDate>
        <author>xxuan@mail.ustc.edu.cn (Xuan)</author>
        <atom:modified>Fri, 22 Jan 2016 17:35:14 +0000</atom:modified>
        <guid>/blogs/2016-01-22-cpp-fundamental-1/</guid>
        <description>some cpp fundamentals ç±»çš„åŸºæœ¬è¯­æ³• ä¸€ä¸ªå…·æœ‰æœ€åŸºç¡€åŠŸèƒ½çš„é“¾è¡¨æ¥å£å¦‚ä¸‹ï¼š template &amp;lt;typename T&amp;gt; class LinkedList { protected: void init() {} //ç§æœ‰åˆå§‹åŒ–å‡½æ•° struct Node{} //é“¾èŠ‚ç‚¹ int ListSize; //é“¾é•¿åº¦ Node* head; //å¤´æŒ‡é’ˆ Node* locate(int index); /</description>
        
        <dc:creator>Xuan</dc:creator>
        
        
        
        
          
            
              <category>cpp</category>
            
          
        
        
        
      </item>
      

    
  </channel>
</rss>